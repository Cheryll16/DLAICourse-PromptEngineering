{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Inferring**\n",
        "\n",
        "In this lesson, we will learn how to infer sentiment and topics from product reviews and news articles."
      ],
      "metadata": {
        "id": "s_eJ_WkePOvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup**"
      ],
      "metadata": {
        "id": "lJMYSedSPsFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "import os\n",
        "\n",
        "\"\"\"\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
        "\"\"\"\n",
        "openai.api_key = \"sk-XXX\""
      ],
      "metadata": {
        "id": "6RrhFuivPrga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3f5a81-4a02-4b92-be53-747f34dbba26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.9-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/75.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1Yw2DPxPKy2"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Product review text**"
      ],
      "metadata": {
        "id": "WSDv8wyyP4Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamp_review = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one had \\\n",
        "additional storage and not too high of a price point. \\\n",
        "Got it fast.  The string to our lamp broke during the \\\n",
        "transit and the company happily sent over a new one. \\\n",
        "Came within a few days as well. It was easy to put \\\n",
        "together.  I had a missing part, so I contacted their \\\n",
        "support and they very quickly got me the missing piece! \\\n",
        "Lumina seems to me to be a great company that cares \\\n",
        "about their customers and products!!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NWXOc2x_P5Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment (positive/negative)**"
      ],
      "metadata": {
        "id": "vMqT5p5EP9ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "s2N-_cFCP_1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3550d3-7e5e-43a1-e427-f127c28db273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the product review is positive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Give your answer as a single word, either \"positive\" \\\n",
        "or \"negative\".\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Jc4tFUpaQC1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc43988-707c-459f-dac0-4a5a0c3384a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Identify types of emotions**"
      ],
      "metadata": {
        "id": "VaxKRK6dQFqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify a list of emotions that the writer of the \\\n",
        "following review is expressing. Include no more than \\\n",
        "five items in the list. Format your answer as a list of \\\n",
        "lower-case words separated by commas.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Aeq2YFqDQHwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64495ff4-9cc0-4ecf-9423-4d763fcf2ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "satisfied, grateful, impressed, pleased, happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Identify anger**"
      ],
      "metadata": {
        "id": "zeeMpF64QLbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Is the writer of the following review expressing anger?\\\n",
        "The review is delimited with triple backticks. \\\n",
        "Give your answer as either yes or no.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Ovs9EIreQMHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cf9aa9-772f-4472-c01a-c82a1ab38ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extract product and company name from customer reviews**"
      ],
      "metadata": {
        "id": "O-MN7eltQwtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text:\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Vnf8Seu5Qy6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec1f0d3-cfbd-4c26-d85f-c5df70455df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Item\": \"lamp\",\n",
            "  \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Doing multiple tasks at once**\n",
        "\n",
        "Require the Model to process multiple requests with one prompt."
      ],
      "metadata": {
        "id": "fQe4vyydQ7yX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text:\n",
        "- Sentiment (positive or negative)\n",
        "- Is the reviewer expressing anger? (true or false)\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "Format the Anger value as a boolean.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Fuyom7xmQ9tq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2433e8d-17e4-4a22-a84c-51b348ce1457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Sentiment\": \"positive\",\n",
            "  \"Anger\": false,\n",
            "  \"Item\": \"lamp\",\n",
            "  \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Inferring topics**"
      ],
      "metadata": {
        "id": "WM0tok8-RAKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story = \"\"\"\n",
        "In a recent survey conducted by the government,\n",
        "public sector employees were asked to rate their level\n",
        "of satisfaction with the department they work at.\n",
        "The results revealed that NASA was the most popular\n",
        "department with a satisfaction rating of 95%.\n",
        "\n",
        "One NASA employee, John Smith, commented on the findings,\n",
        "stating, \"I'm not surprised that NASA came out on top.\n",
        "It's a great place to work with amazing people and\n",
        "incredible opportunities. I'm proud to be a part of\n",
        "such an innovative organization.\"\n",
        "\n",
        "The results were also welcomed by NASA's management team,\n",
        "with Director Tom Johnson stating, \"We are thrilled to\n",
        "hear that our employees are satisfied with their work at NASA.\n",
        "We have a talented and dedicated team who work tirelessly\n",
        "to achieve our goals, and it's fantastic to see that their\n",
        "hard work is paying off.\"\n",
        "\n",
        "The survey also revealed that the\n",
        "Social Security Administration had the lowest satisfaction\n",
        "rating, with only 45% of employees indicating they were\n",
        "satisfied with their job. The government has pledged to\n",
        "address the concerns raised by employees in the survey and\n",
        "work towards improving job satisfaction across all departments.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Us965ZvSRCYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Infer 5 topics** in the given text."
      ],
      "metadata": {
        "id": "e7Z44PHBRLgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine five topics that are being discussed in the \\\n",
        "following text, which is delimited by triple backticks.\n",
        "\n",
        "Make each item one or two words long.\n",
        "\n",
        "Format your response as a list of items separated by commas.\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "lnatfd7UROUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a440c4-5372-4bef-af46-3ff01db1330c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Government survey\n",
            "2. Employee satisfaction\n",
            "3. NASA\n",
            "4. Social Security Administration\n",
            "5. Job satisfaction improvement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Please Note:** The output looks different from the output of instructor in form of: \"goverment survey, job satisfaction, nasa...\". It is normal that the same prompts lead to different output. But we can check what the output fails and interatively improve it (corresponding to **Course III Iterative Prompt Development**). Following is my modified version to get a similar output compared to the instructor's."
      ],
      "metadata": {
        "id": "UUDL8MiaT0um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine five topics that are being discussed in the \\\n",
        "following text, which is delimited by triple backticks.\n",
        "\n",
        "Make each item no more than two words.\n",
        "\n",
        "Format your response as a list of items separated by commas \\\n",
        "without numbering them and print them out in one line.\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYgqhvWjn1m2",
        "outputId": "57fbc755-4dd9-4432-a94a-d8ce570a3896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "survey, satisfaction, NASA, Social Security Administration, job satisfaction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interesting point:**\n",
        "\n",
        "1. To give the answer a length limitation, you would better write \"NO MORE THAN TWO WORDS LONG\" other than \"with ONE OR TWO WORDS LONG\" (I also wrote the same opinion in the note of **Course IV: Summarizing**).\n",
        "1. Compared to the format of the outputs, we may consider that whether the model could understand \"list\" in the meaning of data structure. I personally think no, it currently do not understand the word \"list\" as a data structure, but rather in natural language as a bullet list. So if we want an output in a more structured and consistent way, we would better express clear how the output should look like. (I know there are now some programming languages especially designed for prompt engineering, but I personally have no experience with them, may try if they will work better later.)\n"
      ],
      "metadata": {
        "id": "wXorNmGSqZVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.split(sep=',')"
      ],
      "metadata": {
        "id": "8NBy4O1qVG6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf5e77a-037d-4c9d-eb99-2deb4113accc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['survey',\n",
              " ' satisfaction',\n",
              " ' NASA',\n",
              " ' Social Security Administration',\n",
              " ' job satisfaction']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Make a news alert for certain topics**"
      ],
      "metadata": {
        "id": "HRIwz6jrVPhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_list = [\n",
        "    \"nasa\", \"local government\", \"engineering\",\n",
        "    \"employee satisfaction\", \"federal government\"\n",
        "]"
      ],
      "metadata": {
        "id": "2Vnxu2hKsHEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compared to example code provided by DeepLearning.AI, I added the prompt \"**Your answer should be written as \"topic name : count\"**\" to get the output in the same format as provided in course, otherwise it will look in a different format. You can delete the sentence and rerun the code. To keep the answer in a structured way, it is alway better to form the answer in json or html."
      ],
      "metadata": {
        "id": "K-_teFD3tUua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine whether each item in the following list of \\\n",
        "topics is a topic in the text below, which\n",
        "is delimited with triple backticks.\n",
        "\n",
        "Give your answer as list with 0 or 1 for each topic.\\\n",
        "Your answer should be written as \"topic name : count\"\n",
        "\n",
        "List of topics: {\", \".join(topic_list)}\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "J9Smc-ugVRrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14c89e7-4649-4fa4-c9ee-0abdd25f3505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nasa : 1\n",
            "local government : 0\n",
            "engineering : 0\n",
            "employee satisfaction : 1\n",
            "federal government : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_dict = {i.split(' : ')[0]: int(i.split(' : ')[1]) for i in response.split(sep='\\n')}\n",
        "if topic_dict['nasa'] == 1:\n",
        "    print(\"ALERT: New NASA story!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u66w3KTBsR7R",
        "outputId": "52aa6173-5c22-4580-ee14-2410bb3357c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALERT: New NASA story!\n"
          ]
        }
      ]
    }
  ]
}